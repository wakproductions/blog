<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Blog Name</title>
  <subtitle>Blog subtitle</subtitle>
  <id>http://blog.url.com/</id>
  <link href="http://blog.url.com/"/>
  <link href="http://blog.url.com/feed.xml" rel="self"/>
  <updated>2017-06-01T01:00:00-04:00</updated>
  <author>
    <name>Blog Author</name>
  </author>
  <entry>
    <title>How to connect to an external Postgres database from a Docker container</title>
    <link rel="alternate" href="http://blog.url.com/2017/06/01/connecting-to-external-postgres-database-with-docker.html"/>
    <id>http://blog.url.com/2017/06/01/connecting-to-external-postgres-database-with-docker.html</id>
    <published>2017-06-01T01:00:00-04:00</published>
    <updated>2017-06-01T22:31:14-04:00</updated>
    <author>
      <name>Article Author</name>
    </author>
    <content type="html">&lt;p&gt;You would think something as simple as connecting to a database on the localhost would be a simple task in Docker. 
Unfortunately, accessing resources the local machine requires some special settings because of the obfuscation caused
by Docker&amp;#39;s virtual networking. To access the Postgres database on my local machine, I had to route around localhost
and connect to it via the machine&amp;#39;s local IP address. The local IP address I pass in using an environment variable
in the docker-compose file like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;version: &amp;#39;3&amp;#39;
services:
  web:
    container_name: myapplication
    build: .
    command: bundle exec rails s -p 3000
    environment:
      - DATABASE_URL=postgres://postgres:postgres@localhost:5432/myapplication
    extra_hosts:
      - localhost:${LOCAL_IP}
    ports:
      - 3030:3000
    tty: true

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In my &lt;code&gt;.env&lt;/code&gt; file I populated &lt;code&gt;LOCAL_IP&lt;/code&gt; with my local IP address&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;LOCAL_IP=192.168.1.143
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I had to make the following change to the &lt;code&gt;listen_addresses&lt;/code&gt; part of my &lt;code&gt;postgresql.conf&lt;/code&gt; file in the Postgres data directory:
This enabled Postgres to bind to and listen in on connections coming through the local IP address.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#------------------------------------------------------------------------------
# CONNECTIONS AND AUTHENTICATION
#------------------------------------------------------------------------------

# - Connection Settings -

# what IP address(es) to listen on;
listen_addresses = &amp;#39;localhost,192.168.1.143&amp;#39;
                                        # comma-separated list of addresses;
                                        # defaults to &amp;#39;localhost&amp;#39;; use &amp;#39;*&amp;#39; for all
                                        # (change requires restart)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I also had to add the following line to &lt;code&gt;pg_hba.conf&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;host    all             all             192.168.1.143/32        trust
&lt;/code&gt;&lt;/pre&gt;
</content>
  </entry>
  <entry>
    <title>Headers matter! Check that your MySQL configuration file is valid!</title>
    <link rel="alternate" href="http://blog.url.com/2017/03/15/headers-matter-double-check-mysql-conf.html"/>
    <id>http://blog.url.com/2017/03/15/headers-matter-double-check-mysql-conf.html</id>
    <published>2017-03-15T02:30:00-04:00</published>
    <updated>2017-03-15T12:34:55-04:00</updated>
    <author>
      <name>Article Author</name>
    </author>
    <content type="html">&lt;p&gt;This morning I discovered that a mysql database I was given management of was improperly configured. When the
database was built, a series of custom &lt;code&gt;innodb_*&lt;/code&gt; settings was applied to the &lt;code&gt;my.cnf&lt;/code&gt; configuration file. This morning
I had a need to change a few settings for performance tuning and discovered that all of these settings were invalid! 
What happened? When the file was originally created the &lt;code&gt;innodb_*&lt;/code&gt; settings were placed in the wrong section. The
file looked something like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#
# The MySQL database server configuration file.
#
[client]
port        = 3306
socket      = /var/run/mysqld/mysqld.sock

[mysqld_safe]
socket      = /var/run/mysqld/mysqld.sock
nice        = 0

[mysqld]
user        = mysql
pid-file    = /var/run/mysqld/mysqld.pid
socket      = /var/run/mysqld/mysqld.sock
port        = 3306
basedir     = /usr
datadir         = /mnt/mysql
tmpdir      = /mnt/mysql/tmp
lc-messages-dir = /usr/share/mysql
skip-external-locking

key_buffer      = 2048M
max_allowed_packet  = 16M
thread_stack        = 192K
thread_cache_size       = 8
myisam-recover         = BACKUP
query_cache_limit   = 64M
query_cache_size        = 32M
log_error = /var/log/mysql/error.log
expire_logs_days    = 10
max_binlog_size         = 100M

[mysqldump]
quick
quote-names
max_allowed_packet  = 16M

[mysql]

[isamchk]
key_buffer      = 16M

innodb_buffer_pool_size           = 4G
innodb_data_file_path             = ibdata1:10M:autoextend
innodb_file_per_table = 1
innodb_flush_method               = O_DIRECT
innodb_flush_log_at_trx_commit=2
innodb_support_xa = 0

innodb_read_io_threads=8
innodb_write_io_threads=8

!includedir /etc/mysql/conf.d/

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;All of the &lt;code&gt;innodb_*&lt;/code&gt; settings were placed under the &lt;code&gt;[isamchk]&lt;/code&gt; section when they should have been placed
under the &lt;code&gt;[mysqld]&lt;/code&gt; section. As a result, mysql was reading these these settings improperly.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;MariaDB [(none)]&amp;gt; SHOW VARIABLES LIKE &amp;#39;innodb%&amp;#39;;
+-------------------------------------------+------------------------+
| Variable_name                             | Value                  |
+-------------------------------------------+------------------------+
| innodb_buffer_pool_size                   | 134217728              | &amp;lt;-- NOT 4G
| innodb_data_file_path                     | ibdata1:10M:autoextend |
| innodb_file_per_table                     | OFF                    | &amp;lt;-- NOT using one file per table
| innodb_flush_log_at_trx_commit            | 1                      | &amp;lt;-- NOT 2
| innodb_flush_method                       |                        | &amp;lt;-- NOT set
| innodb_support_xa                         | ON                     | &amp;lt;-- should be OFF
| innodb_read_io_threads                    | 4                      | &amp;lt;-- should be 8
| innodb_write_io_threads                   | 4                      | &amp;lt;-- should be 8
+-------------------------------------------+------------------------+
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Notably, due to the sheer size of the data to be processed we want this system to have a single InnoDB file per
table... but with these corrupted settings I discovered that all this time the DB was being writting in a single
&lt;code&gt;ibdata1&lt;/code&gt; file:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;__AWS_PRODUCTION__ ubuntu@ip-172-31-39-165:~$ ls /mnt/mysql -lh
total 251G
-rw-rw---- 1 mysql mysql  16K Mar 15 15:27 aria_log.00000001
-rw-rw---- 1 mysql mysql   52 Mar 15 15:27 aria_log_control
-rw-r--r-- 1 root  root     0 Feb  6 18:25 debian-5.5.flag
-rw-r--r-- 1 root  root     0 Feb  6 18:33 foo.txt
-rw-rw---- 1 mysql mysql 251G Mar 15 15:27 ibdata1
-rw-rw---- 1 mysql mysql 5.0M Mar 15 15:28 ib_logfile0
-rw-rw---- 1 mysql mysql 5.0M Mar 15 15:24 ib_logfile1
drwx------ 2 root  root   16K Feb  6 18:33 lost+found
drwxr-xr-x 2 mysql root  4.0K Feb  6 18:25 mysql
-rw------- 1 root  root    14 Feb  6 18:25 mysql_upgrade_info
drwx------ 2 mysql mysql 4.0K Feb  6 18:25 performance_schema
drwx------ 2 mysql mysql 4.0K Mar 11 07:39 regdata_production
drwxrwxrwx 2 root  root  4.0K Mar 15 15:28 tmp
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Converting the data tables to one-file-per-table&lt;/h2&gt;

&lt;p&gt;So once I fixed the settings I still had the problem of all of my data being in that single &lt;code&gt;ibdata1&lt;/code&gt; file when we 
really wanted a single table per file. I found &lt;a href="https://dev.mysql.com/doc/refman/5.6/en/tablespace-enabling.html"&gt;this article&lt;/a&gt; which showed that converting each table was as 
easy as running an &lt;code&gt;ALTER TABLE&lt;/code&gt; statement like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;MariaDB [regdata_production]&amp;gt; ALTER TABLE reporters ENGINE=InnoDB;
Query OK, 249757 rows affected (7.99 sec)              
Records: 249757  Duplicates: 0  Warnings: 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Problem solved!&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>How to Resize a Volume in AWS</title>
    <link rel="alternate" href="http://blog.url.com/2017/03/03/how-to-resize-a-volume-in-aws.html"/>
    <id>http://blog.url.com/2017/03/03/how-to-resize-a-volume-in-aws.html</id>
    <published>2017-03-03T01:30:00-05:00</published>
    <updated>2017-03-03T19:08:04-05:00</updated>
    <author>
      <name>Article Author</name>
    </author>
    <content type="html">&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/1Brbqkzqvjw" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;

&lt;h1&gt;Useful Unix Commands&lt;/h1&gt;

&lt;p&gt;&lt;code&gt;$ df -h&lt;/code&gt; - gives the disk usage&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ df -h
Filesystem      Size  Used Avail Use% Mounted on
udev            7.5G   12K  7.5G   1% /dev
tmpfs           1.5G  392K  1.5G   1% /run
/dev/xvda1      7.8G  5.9G  1.6G  80% /
none            4.0K     0  4.0K   0% /sys/fs/cgroup
none            5.0M     0  5.0M   0% /run/lock
none            7.5G     0  7.5G   0% /run/shm
none            100M     0  100M   0% /run/user
/dev/xvdc       296G  136G  147G  49% /mnt/mysql
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;$ sudo file -s /dev/xvd*&lt;/code&gt; - gives information about the available volumes&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo file -s /dev/xvd*
/dev/xvda:  x86 boot sector
/dev/xvda1: Linux rev 1.0 ext4 filesystem data, UUID=240ad8b1-c46c-4ed6-b233-02b4d2a7ede3, volume name &amp;quot;cloudimg-rootfs&amp;quot; (needs journal recovery) (extents) (large files) (huge files)
/dev/xvdb:  FoxPro FPT, blocks size 0, next free block index 1664118375
/dev/xvdc:  Linux rev 1.0 ext4 filesystem data, UUID=72ebf16a-eedc-432a-9364-1e4a9f311aad (needs journal recovery) (extents) (large files) (huge files)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;$ sudo resize2fs /dev/xvda1&lt;/code&gt; - expands the given volume xvda1 to take up the newly allocated space (works only on ext4) file system&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ sudo resize2fs /dev/xvdc
resize2fs 1.42.9 (4-Feb-2014)
Filesystem at /dev/xvdc is mounted on /mnt/mysql; on-line resizing required
old_desc_blocks = 19, new_desc_blocks = 69
The filesystem on /dev/xvdc is now 288358400 blocks long.
&lt;/code&gt;&lt;/pre&gt;
</content>
  </entry>
  <entry>
    <title>How to Install Ruby on a Production System with Ansible</title>
    <link rel="alternate" href="http://blog.url.com/2017/02/28/install-ruby-on-a-production-system.html"/>
    <id>http://blog.url.com/2017/02/28/install-ruby-on-a-production-system.html</id>
    <published>2017-02-28T01:30:00-05:00</published>
    <updated>2017-02-28T09:58:22-05:00</updated>
    <author>
      <name>Article Author</name>
    </author>
    <content type="html">&lt;p&gt;I recently had to set up a production server to run Ruby. Surprisingly there are many opinions on how to do it. Some
people use RVM or RBenv, but I&amp;#39;ve been told by other people who have tried that that in a production system the system
hacks those package managers use to get the magic to work can have unintended side effects. For example, RVM&amp;#39;s override
of the shell causes problems when trying to use Ruby with UNIX cron jobs.&lt;/p&gt;

&lt;p&gt;Doing the build-from-scratch install of system Ruby seems to be the best option for setting up a production server.
&lt;a href="http://robmclarty.com/blog/how-to-setup-a-production-server-for-rails-4"&gt;I found this useful blog article&lt;/a&gt;, which I&amp;#39;m reposting an excerpt here in case it ever disappears from the Internet. The setup
process should be largely the same for any other versions of Ruby.&lt;/p&gt;

&lt;h3&gt;Excerpt from robmclarty.com&lt;/h3&gt;

&lt;p&gt;I wanted to setup the bleeding edge on this server, so I went with a source code install process for Ruby rather than a pre-existing package. I installed Ruby 2.0 and Rails 4.beta. What I usually do to keep track of my source-code-installed components is create a src directory in my user&amp;#39;s home folder inside which I store all my source code folders for compilation, installation, and later, any uninstallation I might need to do.&lt;/p&gt;

&lt;p&gt;But before that, I needed to install a few more dependencies so my server environment was ready for it.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt-get install build-essential libyaml-dev libsqlite3-0 libsqlite3-dev sqlite3 libxml2-dev libxslt-dev autoconf libc6-dev ncurses-dev automake libtool bison subversion
Next, inside /home/bill/src and got the latest Ruby, decompressed it, configured, compiled, and installed.

wget ftp://ftp.ruby-lang.org/pub/ruby/2.0/ruby-2.0.0-p0.tar.gz
tar xzvf ruby-2.0.0-p0.tar.gz
cd ruby-2.0.0-p0
./configure
make
sudo make install
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next, I made a symbolic link from /usr/local/bin/ruby to /usr/bin/ruby because some programs look for it there.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo ln -s /usr/local/bin/ruby /usr/bin/ruby
The newer Rubies come with rubygems so you don&amp;#39;t need to worry about installing that separately anymore. But before installing any new gems (like Rails) it&amp;#39;s always a good idea to make sure it&amp;#39;s up to date.

sudo gem update --system
Finally, now that there was a convenient beta1 branch for the Rails gem, all I needed to do was install the latest Rails was the following.

sudo gem install rails --version 4.0.0.beta1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I encountered some weird issues with rdoc and ri where I had to answer &amp;quot;yes&amp;quot; to overwrite the existing versions. I just went with it since this is a dedicated server and I care more about the app working than some documentation that isn&amp;#39;t necessary for me in production. I&amp;#39;m sure this will be fixed in the final release.&lt;/p&gt;

&lt;p&gt;Update: @kaspergrubbe gave me a great little tweak so you don&amp;#39;t need to specify --no-ri --no-rdoc every time you install a gem in production: just add gem: --no-rdoc --no-ri to ~/.gemrc (create that file if it doesn&amp;#39;t already exist) and don&amp;#39;t worry about ri or rdoc again in production.&lt;/p&gt;

&lt;h1&gt;Throw in some Ansible&lt;/h1&gt;

&lt;p&gt;I automated these steps using Ansible to install Ruby 2.3.3 on my system. &lt;a href="https://github.com/wakproductions/ansible-examples/blob/master/roles/web/tasks/install_ruby233.yml"&gt;Here&amp;#39;s the playbook.&lt;/a&gt;&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Pretty Print a Really Big Hash in Ruby</title>
    <link rel="alternate" href="http://blog.url.com/2017/02/16/pretty-print-a-really-big-hash-to-string-in-ruby.html"/>
    <id>http://blog.url.com/2017/02/16/pretty-print-a-really-big-hash-to-string-in-ruby.html</id>
    <published>2017-02-16T01:30:00-05:00</published>
    <updated>2017-02-16T13:00:57-05:00</updated>
    <author>
      <name>Article Author</name>
    </author>
    <content type="html">&lt;h2&gt;Problem: Copy and paste a really big Ruby object so that it&amp;#39;s human readable&lt;/h2&gt;

&lt;p&gt;Today I was building a fixture in one of my RSpec tests which consisted of a really big hash. It looked something like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;really_big_hash =     {:Profile=&amp;gt;
                         {:CharterNumber=&amp;gt;&amp;quot;68448&amp;quot;,
                          :CreditUnionId=&amp;gt;&amp;quot;14241&amp;quot;,
                          :CreditUnionName=&amp;gt;&amp;quot;CITIZENS EQUITY FIRST&amp;quot;,
                          :CycleDate=&amp;gt;&amp;quot;12/31/2015&amp;quot;,
                          :CreditUnionTypeID=&amp;gt;&amp;quot;FISCU&amp;quot;,
                          :Region=&amp;gt;&amp;quot;4&amp;quot;,
                          :CreditUnionStatus=&amp;gt;&amp;quot;Active&amp;quot;,
                          :DateChartered=&amp;gt;&amp;quot;2000&amp;quot;,
                          :DateInsured=&amp;gt;&amp;quot;1/2/1975&amp;quot;,
                          :CharterStateCode=&amp;gt;&amp;quot;Illinois&amp;quot;,
                          :TOM_CODE=&amp;gt;&amp;quot;99&amp;quot;,
                          :State=&amp;gt;&amp;quot;IL&amp;quot;,
                          :Acct_896=&amp;gt;&amp;quot;1&amp;quot;,
                          :PeerGroup=&amp;gt;&amp;quot;6 - $500,000,000 and greater&amp;quot;,
                          :Assets=&amp;gt;&amp;quot;5174819725&amp;quot;,
                          :NumberOfMembers=&amp;gt;&amp;quot;312929&amp;quot;,
                          :IsLowIncome=&amp;gt;&amp;quot;No&amp;quot;,
                          :CertificationDate=&amp;gt;&amp;quot;1/22/2016 10:46:28 AM&amp;quot;,
                          :HasWebSite=&amp;gt;&amp;quot;Yes&amp;quot;,
                           ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When I tried to copy this fixture into my test file, I initially did this in console:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;require &amp;#39;clipboard&amp;#39; # use the Clipboard gem
Clipboard.copy(really_big_hash)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The problem was that when I pasted the text it all ended up on one line like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;{:Profile=&amp;gt;{:CharterNumber=&amp;gt;&amp;quot;68448&amp;quot;, :CreditUnionId=&amp;gt;&amp;quot;14241&amp;quot;, :CreditUnionName=&amp;gt;&amp;quot;CITIZENS EQUITY FIRST&amp;quot;, :CycleDate=&amp;gt;...
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Solution: Ruby&amp;#39;s &amp;#39;pp&amp;#39; module&lt;/h2&gt;

&lt;p&gt;I discovered that the Ruby &amp;#39;pp&amp;#39; module could be used to format a Hash as a multiline output and I could capture the
output. Here&amp;#39;s what I did:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;require &amp;#39;pp&amp;#39;
cap = StringIO.new
$stdout = cap
pp(r)
$stdout = STDOUT

Clipboard.copy(cap.string)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I was then able to paste my Hash as a more human-readable multi-line string. Note that because &lt;code&gt;pp&lt;/code&gt; prints to screen
by default, I had to reroute &lt;code&gt;$stdout&lt;/code&gt; temporarily to capture the output via a &lt;code&gt;StringIO&lt;/code&gt; object.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Better Bulk Inserts in Rails</title>
    <link rel="alternate" href="http://blog.url.com/2017/01/14/bulk-insert-in-rails-and-mysql.html"/>
    <id>http://blog.url.com/2017/01/14/bulk-insert-in-rails-and-mysql.html</id>
    <published>2017-01-14T01:30:00-05:00</published>
    <updated>2017-01-14T23:46:42-05:00</updated>
    <author>
      <name>Article Author</name>
    </author>
    <content type="html">&lt;p&gt;One of the limitations of Rails is that it doesn&amp;#39;t do a true bulk insert. For example, let&amp;#39;s say you have a &lt;code&gt;MenuItem&lt;/code&gt;
model and pass it an array of objects to create like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;items_to_create = [
  {
    name: &amp;#39;Sandwich&amp;#39;,
    description: &amp;#39;Chips included&amp;#39;,
    price: 10.00,
  },
  {
    name: &amp;#39;Soup&amp;#39;,
    description: &amp;#39;Cream of mushroom&amp;#39;,
    price: 3.00    
  },
  {
    name: &amp;#39;Salmon&amp;#39;,
    description: &amp;#39;Pan seared&amp;#39;,
    price: 17.00
  },
]

MenuItem.create!(items_to_create)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When you call &lt;code&gt;MenuItem.create!&lt;/code&gt;, ActiveRecord will actually perform 3 separate INSERT queries on the database rather 
than one bulk insert query. It will look something like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class="sql"&gt;INSERT INTO models (...) VALUES (...);
INSERT INTO models (...) VALUES (...);
INSERT INTO models (...) VALUES (...);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The problem with this approach is that it is inefficient - DB engines are much faster at peforming INSERT when fed the 
data all at once. I&amp;#39;m working on a project that requires a huge manipulation of data and thus many DB queries. To make 
it run faster I&amp;#39;ve tried to minimize the number of individual queries. One way that I was able to speed this up is to 
build my own native bulk insert routine for ActiveRecord that works with MySQL. Here is the code:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;# app/models/concerns/has_bulk_insert.rb

module HasBulkInsert
  extend ActiveSupport::Concern

  included do
  end

  class_methods do
    BI_IGNORE_COLUMNS=%w(id)

    def bulk_insert(values_array)
      return if values_array.empty?
      ActiveRecord::Base.connection.execute bi_sql(values_array)
    end

    protected
    def bi_column_definitions
      self
        .columns_hash
        .map {|col,props| BI_IGNORE_COLUMNS.include?(col) ? nil : {col=&amp;gt;props.type} }
        .compact
        .reduce({}, :merge)
    end

    def bi_escaped_column_names
      bi_column_definitions.reduce([]) { |m,(k,v)| m &amp;lt;&amp;lt; &amp;quot;`#{k}`&amp;quot; }.join(&amp;#39;,&amp;#39;)
    end

    def bi_sql(values_array)
      &amp;lt;&amp;lt;SQL
INSERT INTO #{self.table_name} (#{bi_escaped_column_names}) VALUES
#{bi_convert_values_array(values_array)};
SQL
    end

    def bi_convert_values_array(values_array)
      values_array.map do |values_hash|
        line_values = bi_column_definitions.reduce([]) do |line, (col,definition)|
          vh = values_hash.stringify_keys

          next line &amp;lt;&amp;lt; &amp;#39;NULL&amp;#39; if vh[col].nil? &amp;amp;&amp;amp; !is_timestamp_column?(col)

          case definition
            when :string, :text
              if is_enum_column?(col)
                line &amp;lt;&amp;lt; &amp;quot;&amp;#39;#{enum_value(col, vh[col])}&amp;#39;&amp;quot;
              else
                line &amp;lt;&amp;lt; &amp;quot;&amp;#39;#{vh[col].gsub(&amp;quot;&amp;#39;&amp;quot;, &amp;quot;&amp;#39;&amp;#39;&amp;quot;)}&amp;#39;&amp;quot;
              end
            when :date
              line &amp;lt;&amp;lt; &amp;quot;&amp;#39;#{vh[col].strftime(&amp;#39;%Y-%m-%d&amp;#39;)}&amp;#39;&amp;quot;
            when :datetime
              if is_timestamp_column?(col)
                line &amp;lt;&amp;lt; &amp;quot;&amp;#39;#{Time.now.strftime(&amp;#39;%Y-%m-%d %H:%M:%S&amp;#39;)}&amp;#39;&amp;quot;
              else
                line &amp;lt;&amp;lt; &amp;quot;&amp;#39;#{vh[col].strftime(&amp;#39;%Y-%m-%d&amp;#39;)}&amp;#39;&amp;quot;
              end
            when :integer
              if vh[col].is_a? Integer
                line &amp;lt;&amp;lt; vh[col].to_s
              elsif vh[col].is_a?(String) &amp;amp;&amp;amp; is_enum_column?(col)
                line &amp;lt;&amp;lt; &amp;quot;&amp;#39;#{enum_value(col, vh[col])}&amp;#39;&amp;quot;
              else
                raise &amp;quot;Unable to interpret data for column #{col}\n#{vh}&amp;quot;
              end
            when :decimal, :boolean
              line &amp;lt;&amp;lt; vh[col].to_s
            else
              raise &amp;quot;Unknown data column type: #{definition}&amp;quot;
          end
        end
        .join(&amp;#39;,&amp;#39;)

        &amp;quot;(#{line_values})&amp;quot;
      end
      .join(&amp;quot;,\n&amp;quot;)
    end

    def enum_value(column_name, enumeration_value)
      self.send(column_name.pluralize)[enumeration_value]
    end

    def is_enum_column?(column_name)
      self.defined_enums.include?(column_name)
    end

    def is_timestamp_column?(column_name)
      %w(created_at updated_at).include?(column_name)
    end
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To use this, all you have to do is include the module in your model like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;class MenuItem &amp;lt; ApplicationRecord
  include HasBulkInsert
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now you can call the method:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;MenuItem.bulk_insert(items_to_create)  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The SQL query used by ActiveRecord will be consolidated to look more like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class="sql"&gt;INSERT INTO models (...) VALUES
  (...),
  (...),
  (...),
  (...),
  ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;One limitation of my code module at this point is that it does not support serialized fields, but it is excellent for
basic tables and speeds things up tremendously - by about 50% in my local bench tests!&lt;/p&gt;

&lt;h3&gt;Related Links&lt;/h3&gt;

&lt;p&gt;&lt;a href="http://stackoverflow.com/questions/1793169/which-is-faster-multiple-single-inserts-or-one-multiple-row-insert"&gt;StackOverflow: Which is faster: single inserts or one multiple row insert?&lt;/a&gt; &lt;/p&gt;
</content>
  </entry>
</feed>
